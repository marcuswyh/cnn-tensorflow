{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_as2_partA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXbZzf2XXiNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "704f487e-3eef-4723-d44c-645700420d89"
      },
      "source": [
        "import h5py\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idXxFbzLXxGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3205c611-a4e5-4e61-c683-0a6fe0cb180b"
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/datasets/data.h5.zip\" -d \"./\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/datasets/data.h5.zip\n",
            "replace ./data1.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WthJgQuCvcvA",
        "colab_type": "text"
      },
      "source": [
        "# PART A TASK 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZCywUNREKoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "\n",
        "\n",
        "def loadDataH5():\n",
        "    with h5py.File('data1.h5','r') as hf:\n",
        "        trainX = np.array(hf.get('trainX'))\n",
        "        trainY = np.array(hf.get('trainY'))\n",
        "        valX = np.array(hf.get('valX'))\n",
        "        valY = np.array(hf.get('valY'))\n",
        "        print (trainX.shape,trainY.shape)\n",
        "        print (valX.shape,valY.shape)\n",
        "    return trainX, trainY, valX, valY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A8vrRVFZoeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class cnn:\n",
        "\n",
        "  @staticmethod\n",
        "  def buildBasic(width,height,depth,classes):\n",
        "    model = tf.keras.Sequential()\n",
        "    inputshape = (height,width,depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3,3), padding='same', input_shape=inputshape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  @staticmethod\n",
        "  def buildVersion1(width,height,depth,classes):\n",
        "    model = tf.keras.Sequential()\n",
        "    inputshape = (height,width,depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3,3), padding='same', input_shape=inputshape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  @staticmethod\n",
        "  def buildVersion2(width,height,depth,classes):\n",
        "    model = tf.keras.Sequential()\n",
        "    inputshape = (height,width,depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3,3), padding='same', input_shape=inputshape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  @staticmethod\n",
        "  def buildVersion3(width,height,depth,classes):\n",
        "    model = tf.keras.Sequential()\n",
        "    inputshape = (height,width,depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16, (3,3), padding='same', input_shape=inputshape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def task1():\n",
        "  \n",
        "  NUM_EPOCHS = 20\n",
        "\n",
        "  # ======================\n",
        "  # CHANGE MODEL TYPE HERE\n",
        "  # ======================\n",
        "  # basic cnn = 0\n",
        "  # 1 extra pool and conv layer = 1\n",
        "  # 2 extra pool and conv layers = 2\n",
        "  # 3 extra pool and conv layers = 3\n",
        "  # data augmentation will prompt to enable for the two deepest network\n",
        "  modelType = 3\n",
        "\n",
        "  # DATA AUGMENTATION VARIABLES (do not change)\n",
        "  augmentData = False\n",
        "  augmentBatch = 8\n",
        "\n",
        "  # load data\n",
        "  trainX, trainY, testX, testY = loadDataH5()\n",
        "  opt = tf.keras.optimizers.SGD(lr=0.01)\n",
        "\n",
        "  if modelType == 0:\n",
        "    model = cnn.buildBasic(width=128,height=128,depth=3,classes=17)\n",
        "  elif modelType == 1:\n",
        "    model = cnn.buildVersion1(width=128,height=128,depth=3,classes=17)\n",
        "  elif modelType == 2:\n",
        "    print(\"Do you want to do data augmentation for this model? [y = yes] [any key = no]\")\n",
        "    inp = input()\n",
        "    if inp == 'y' or inp=='Y':\n",
        "      augmentData = True\n",
        "    model = cnn.buildVersion2(width=128,height=128,depth=3,classes=17)\n",
        "  elif modelType == 3:\n",
        "    print(\"Do you want to do data augmentation for this model? [y = yes] [any key = no]\")\n",
        "    inp = input()\n",
        "    if inp == 'y' or inp=='Y':\n",
        "      augmentData = True\n",
        "    model = cnn.buildVersion3(width=128,height=128,depth=3,classes=17)\n",
        "  else:\n",
        "    print (\"wrong model type input\")\n",
        "    quit()\n",
        "\n",
        "  if augmentData:\n",
        "    aug= tf.keras.preprocessing.image.ImageDataGenerator( rotation_range=20, width_shift_range=0.1, shear_range=0.2, zoom_range=0.4, horizontal_flip=True)\n",
        "    trainGenerator= aug.flow(trainX, trainY, batch_size=32)\n",
        "\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "  print (model.summary())\n",
        "\n",
        "  if augmentData:\n",
        "    H = model.fit(trainGenerator,validation_data=(testX,testY),batch_size=1,epochs=NUM_EPOCHS, steps_per_epoch= len(trainX)/ augmentBatch)\n",
        "  else:\n",
        "    H = model.fit(trainX,trainY,validation_data=(testX,testY),batch_size=1,epochs=NUM_EPOCHS)\n",
        "\n",
        "  print (\"Test Data Loss and Accuracy: \", model.evaluate(testX, testY))\n",
        "\n",
        "  # plot the training loss and accuracy\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "task1()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sui1tQsyvR_z",
        "colab_type": "text"
      },
      "source": [
        "# PART A TASK 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ_ZJ-gEt3G2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "92f6e271-9282-4f80-f0e1-944e6eddddac"
      },
      "source": [
        "class models:\n",
        "\n",
        "  def shallowVGG(width,height,depth,classes):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    inputShape= (height, width, depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def AlexNet(width,height,depth,classes):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    inputShape= (height, width, depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(96, (11, 11), strides=4, padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(384, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(384, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(9216,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(4096,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(4096,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def LeNet(width,height,depth,classes):\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    inputShape= (height, width, depth)\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(20, (5, 5), padding=\"same\",input_shape=inputShape, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(50, (5, 5), padding=\"same\", activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def ensemble(modelName, width, height, depth, classes):\n",
        "  if modelName == \"ShallowVGG\":\n",
        "    return models.shallowVGG(width, height, depth, classes)\n",
        "  elif modelName == \"AlexNet\":\n",
        "    return models.AlexNet(width, height, depth, classes)\n",
        "  elif modelName == \"LeNet\":\n",
        "    return models.LeNet(width, height, depth, classes)\n",
        "  elif modelName == \"VGG16\":\n",
        "    return tf.keras.applications.VGG16(weights=None, input_shape=(width, height, depth), classes=classes)\n",
        "  elif modelName == \"Inception\":\n",
        "    return tf.keras.applications.InceptionV3(weights=None, input_shape=(width, height, depth), classes=classes)\n",
        "  elif modelName == \"ResNet\":\n",
        "    return tf.keras.applications.ResNet50(weights=None, input_shape=(width, height, depth), classes=classes)\n",
        "\n",
        "\n",
        "def task2():\n",
        "\n",
        "  NUM_EPOCHS = 50\n",
        "  TRAIN = False # set to TRUE to re-train all base learners to get new weights\n",
        "\n",
        "  trainX, trainY, testX, testY = loadDataH5()\n",
        "  opt = tf.keras.optimizers.SGD(lr=0.01)\n",
        "  augmentBatch = 8\n",
        "\n",
        "  modelnames = [\"ResNet\",\"Inception\",\"VGG16\",\"AlexNet\",\"LeNet\",\"ShallowVGG\"]\n",
        "\n",
        "  # TRAINING FOR ALL BASE LEARNERS\n",
        "  if TRAIN:\n",
        "    for name in modelnames:\n",
        "      if name != \"ResNet\" or name != \"Inception\" or name != \"VGG16\":\n",
        "        model = ensemble(name,width=128,height=128,depth=3,classes=17)\n",
        "\n",
        "        # data augmentation\n",
        "        aug= tf.keras.preprocessing.image.ImageDataGenerator( rotation_range=20, width_shift_range=0.1, shear_range=0.2, zoom_range=0.4, horizontal_flip=True)\n",
        "        trainGenerator= aug.flow(trainX, trainY, batch_size=32)\n",
        "\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "        print (model.summary())\n",
        "\n",
        "        # initialize checkpoint to monitor best validation loss\n",
        "        # save weights to drive\n",
        "        fname = \"/content/gdrive/My Drive/Deeplearning/weights/weights.\"+name+\".hdf5\"\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "\n",
        "        H = model.fit(trainGenerator,validation_data=(testX,testY),batch_size=1,epochs=NUM_EPOCHS, steps_per_epoch= len(trainX)/ augmentBatch, callbacks=[checkpoint])\n",
        "\n",
        "        print (\"Test Data Loss and Accuracy: \", model.evaluate(testX, testY))\n",
        "\n",
        "        # plot the training loss and accuracy\n",
        "        plt.style.use(\"ggplot\")\n",
        "        plt.figure()\n",
        "        plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
        "        plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "        plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "        plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "        plt.title(\"Training Loss and Accuracy\")\n",
        "        plt.xlabel(\"Epoch #\")\n",
        "        plt.ylabel(\"Loss/Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "  # PREDICTIONS FOR ALL BASE LEARNERS\n",
        "  print (\"Predicting base learners\")\n",
        "  all_predictions = np.zeros((340,17))\n",
        "  for name in modelnames:\n",
        "    model = ensemble(name,width=128,height=128,depth=3,classes=17)\n",
        "\n",
        "    # load weights from drive\n",
        "    fname = \"/content/gdrive/My Drive/Deeplearning/weights/weights.\"+name+\".hdf5\"\n",
        "    model.load_weights(fname)\n",
        "    \n",
        "    opt = tf.keras.optimizers.SGD(lr=0.01)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "    predictions = model.predict(testX)\n",
        "    print (\"Prediction accuracy of\", name,\":\", np.sum(np.argmax(predictions, axis=1) == testY)/len(testY))\n",
        "    all_predictions += predictions\n",
        "\n",
        "  # AVERAGING PREDICTIONS TO OBTAIN ENSEMBLE PREDICTIONS ACCURACY\n",
        "  average = all_predictions / len(modelnames)\n",
        "  final_pred = np.argmax(average, axis=1)\n",
        "  print()\n",
        "  print(\"Final ensemble accuracy:\",np.sum(final_pred == testY)/len(testY))\n",
        "\n",
        "\n",
        "task2()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1020, 128, 128, 3) (1020,)\n",
            "(340, 128, 128, 3) (340,)\n",
            "Predicting base learners\n",
            "Prediction accuracy of ResNet : 0.7823529411764706\n",
            "Prediction accuracy of Inception : 0.8\n",
            "Prediction accuracy of VGG16 : 0.6676470588235294\n",
            "Prediction accuracy of AlexNet : 0.7176470588235294\n",
            "Prediction accuracy of LeNet : 0.6970588235294117\n",
            "Prediction accuracy of ShallowVGG : 0.7\n",
            "\n",
            "Final ensemble accuracy: 0.8294117647058824\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}